{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into everything Convolution Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will take a deep dive in the inner works of CNNS, there use and much more.\n",
    "\n",
    "Examples of how to use them for computer vision tasks is covered in PyTorchLearning/Computervision.ipynb, this notebook will try to avoid the simple \"model building\" code and try to explain how and why they work.\n",
    " \n",
    "This book may be updated in the future to include code examples of each (as rn it being a ipynb makes no sense it could just be a pdf) if I have time or want to consolidate knowledge more but not best use of time rn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can take a deep look at the individual components of CNNs we first need to loop at the broader structure. \n",
    "\n",
    "CNN layers are made of up the following \n",
    "\n",
    "* Convolution operation\n",
    "* Non-Linearity (Activation functions)\n",
    "* Repeat as many times as want\n",
    "* Pooling\n",
    "* Again can repeat multiple times.\n",
    "\n",
    "The convolution operation/layer itself comprises *\n",
    "a kernal\n",
    "\n",
    ", a filter if you like that is much smaller then the image and which undergoes convolution with the image.\n",
    "As well as the kernal the convolution layer has \n",
    "\n",
    "* stride\n",
    "* padding\n",
    "\n",
    "and we will go into what these are later.\n",
    "\n",
    "The pooling layer is a technique that allows the dimension of an image to be reduced, often useful to be able to reduce the computation needed and useful to extract only useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put it simply the convoltuion is a mathmatical tool denoted by \n",
    "$$\n",
    "S(t) = (I * K)(t) = \\int I(a)K(t-a)da\n",
    "$$ \n",
    "where I is the input, in our case an image, and K is a kernal. As our images are typically descrete it is often more useful to use \n",
    "$$S(t) = \\sum I(a)K(t-a)$$\n",
    "\n",
    "In general our image is often multidimensional, and so need to convolute over multiple axis, so we get \n",
    "$$S(i, j) = (I * K)(i, j) = \\sum \\sum I(m, n)K(i - m, j - n)$$\n",
    ", and as this is a commutative operation it can be equally written the other way around.\n",
    "\n",
    "Usually neural network libraries implement a related functio ncalled cross-correlation, which is the convolution but without flipping the kernal,\n",
    "\n",
    "$$ S(i, j) = \\sum \\sum I(i + m, j +n)K(m, n) $$\n",
    "\n",
    "many libraries implement this function under the disguise of convolution and as such we will follow the same notation.\n",
    "\n",
    "There is no actual difference to the face that the kernal is not flipped, as in deep learning we are interested in learning the weights on the kernal (filter) thus it learns them in the appropiate place, and if we were to learn using actual convolution it would be be a flipped version of said kernal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The kernal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CNNs, the kernal (filters) are not predefined and are learnt through backpropagation like weights in a sequential neural network.\n",
    "\n",
    "The kernals are typically  $K x K$ in size (for 2D), where K is often much smaller then the image size (3, 5 or 7). The size of the image after being convoluted with a kernal is dependent on \n",
    "* Stride\n",
    "* Padding\n",
    "* Input size\n",
    "* Kernal size\n",
    "\n",
    "Stride is how far over we move the kernal the image, example stride of 1 means we move one pixel at a time.\n",
    "\n",
    "Padding is how many extra zero pixels are added to the boarder of an image, same padding is when the padded is added to so that the input and output image have the same size.\n",
    "\n",
    "The output size are given by the following equation\n",
    "$$\n",
    "H_{out} = \\frac{H - K + 2P}{S} + 1\n",
    "$$\n",
    "$$\n",
    "W_{out} = \\frac{W - K + 2P}{S} + 1\n",
    "$$.\n",
    "\n",
    "\n",
    "There are some typical kernals used for things like edge detection, sharpening features, smoothing images and so on but those are not going to be looked at here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling is a technique used in CNN's to reduce the dimensionality of the input feature maps that helps in several ways:\n",
    "* Dimensionality reduciton : helps decrease overfitting\n",
    "* Feature extraction : It captures the most import features\n",
    "* Translation invariance : Pooling layers helps make the model invarient to small translations on the input space.\n",
    "\n",
    "There are serveral different types of pooling:\n",
    "* Max\n",
    "* Average\n",
    "* Global Average \n",
    "* Global Max\n",
    "\n",
    "Pooling has a couple of characeristics\n",
    "* Window size - size of the pooling kernal\n",
    "* Stride\n",
    "* Padding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
